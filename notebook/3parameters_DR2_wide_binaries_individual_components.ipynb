{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from scipy.spatial import Delaunay, cKDTree\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from numpy.lib.recfunctions import append_fields\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55507 (numpy.record, [('source_id2', '>i8'), ('ra2', '>f8'), ('dec2', '>f8'), ('astrometric_chi2_al_2', '>f8'), ('astrometric_n_good_obs_al2', '>i8'), ('phot_g_mean_flux_over_error2', '>f8'), ('phot_rp_mean_flux_over_error2', '>f8'), ('phot_bp_mean_flux_over_error2', '>f8'), ('phot_bp_rp_excess_factor2', '>f8'), ('pmra2', '>f8'), ('pmra_error2', '>f8'), ('pmdec2', '>f8'), ('pmdec_error2', '>f8'), ('phot_g_mean_mag2', '>f8'), ('phot_bp_mean_mag2', '>f8'), ('phot_rp_mean_mag2', '>f8'), ('parallax2', '>f8'), ('parallax_over_error2', '>f8'), ('radial_velocity2', '>f8'), ('radial_velocity_error2', '>f8'), ('rv_nb_transits2', '>i8'), ('source_id', '>i8'), ('ra', '>f8'), ('dec', '>f8'), ('pmra', '>f8'), ('pmra_error', '>f8'), ('pmdec', '>f8'), ('pmdec_error', '>f8'), ('phot_g_mean_mag', '>f8'), ('phot_bp_mean_mag', '>f8'), ('phot_rp_mean_mag', '>f8'), ('parallax', '>f8'), ('parallax_over_error', '>f8'), ('astrometric_chi2_al', '>f8'), ('astrometric_n_good_obs_al', '>i8'), ('phot_g_mean_flux_over_error', '>f8'), ('phot_rp_mean_flux_over_error', '>f8'), ('phot_bp_mean_flux_over_error', '>f8'), ('phot_bp_rp_excess_factor', '>f8'), ('radial_velocity', '>f8'), ('radial_velocity_error', '>f8'), ('rv_nb_transits', '>i8'), ('pairdistance', '>f8'), ('binary_class', 'S4'), ('s_AU', '>f8'), ('ruwe', '>f8'), ('ruwe2', '>f8'), ('a0_prior', '>f8'), ('dist', '>f8'), ('phot_g_mean_mag_error', '<f8'), ('phot_g_mean_mag_error2', '<f8'), ('phot_rp_mean_mag_error', '<f8'), ('phot_rp_mean_mag_error2', '<f8'), ('phot_bp_mean_mag_error', '<f8'), ('phot_bp_mean_mag_error2', '<f8'), ('parallax_error', '<f8'), ('parallax_error2', '<f8'), ('mean_acceptance_fraction', '<f8'), ('lnprob', '<f8'), ('lnprob_lower', '<f8'), ('lnprob_upper', '<f8'), ('teff', '<f8'), ('teff_lower', '<f8'), ('teff_upper', '<f8'), ('logg', '<f8'), ('logg_lower', '<f8'), ('logg_upper', '<f8'), ('feh', '<f8'), ('feh_lower', '<f8'), ('feh_upper', '<f8'), ('mass', '<f8'), ('mass_lower', '<f8'), ('mass_upper', '<f8'), ('age', '<f8'), ('age_lower', '<f8'), ('age_upper', '<f8'), ('a0', '<f8'), ('a0_lower', '<f8'), ('a0_upper', '<f8'), ('logl', '<f8'), ('logl_lower', '<f8'), ('logl_upper', '<f8'), ('mean_acceptance_fraction2', '<f8'), ('lnprob2', '<f8'), ('lnprob_lower2', '<f8'), ('lnprob_upper2', '<f8'), ('teff2', '<f8'), ('teff_lower2', '<f8'), ('teff_upper2', '<f8'), ('logg2', '<f8'), ('logg_lower2', '<f8'), ('logg_upper2', '<f8'), ('feh2', '<f8'), ('feh_lower2', '<f8'), ('feh_upper2', '<f8'), ('mass2', '<f8'), ('mass_lower2', '<f8'), ('mass_upper2', '<f8'), ('age2', '<f8'), ('age_lower2', '<f8'), ('age_upper2', '<f8'), ('a02', '<f8'), ('a0_lower2', '<f8'), ('a0_upper2', '<f8'), ('logl2', '<f8'), ('logl_lower2', '<f8'), ('logl_upper2', '<f8')])\n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "data = fits.getdata('../data/Elbadry_200pc_binaries_v2_ruwe_a0_prior.fits')\n",
    "data = data.view(np.recarray)\n",
    "data = append_fields(data,\"phot_g_mean_mag_error\",np.divide(1.086,data.phot_g_mean_flux_over_error),\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"phot_g_mean_mag_error2\",np.divide(1.086,data.phot_g_mean_flux_over_error2),\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"phot_rp_mean_mag_error\",np.divide(1.086,data.phot_rp_mean_flux_over_error),\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"phot_rp_mean_mag_error2\",np.divide(1.086,data.phot_rp_mean_flux_over_error2),\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"phot_bp_mean_mag_error\",np.divide(1.086,data.phot_bp_mean_flux_over_error),\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"phot_bp_mean_mag_error2\",np.divide(1.086,data.phot_bp_mean_flux_over_error2),\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"parallax_error\",np.divide(1,data.parallax_over_error)*data.parallax,\n",
    "                     usemask=False, asrecarray=True)\n",
    "data = append_fields(data,\"parallax_error2\",np.divide(1,data.parallax_over_error2)* data.parallax2,\n",
    "                     usemask=False, asrecarray=True)\n",
    "\n",
    "# Add new fields:\n",
    "array = np.zeros(len(data))\n",
    "components = [\"\",\"2\"]\n",
    "\n",
    "quality_names = ['mean_acceptance_fraction']\n",
    "\n",
    "percentiles = [\"\",\"_lower\",\"_upper\"]\n",
    "field_names = ['lnprob','teff','logg','feh','mass','age','a0','logl']\n",
    "array_list = []\n",
    "name_list = []\n",
    "for component in components:\n",
    "    for quality_name in quality_names:\n",
    "        array_list.append(array)\n",
    "        name_list.append(quality_name + component)\n",
    "    for field_name in field_names:\n",
    "        for percentile in percentiles:\n",
    "            array_list.append(array)\n",
    "            name_list.append(field_name + percentile + component)\n",
    "data = append_fields(data,name_list,array_list,usemask=False, asrecarray=True)\n",
    "print(len(data), data.dtype)\n",
    "# correct for the G magnitude systematic error\n",
    "g_corr = np.copy(data.phot_g_mean_mag)\n",
    "cut = (data.phot_g_mean_mag <= 6)\n",
    "g_corr[cut] = data.phot_g_mean_mag[cut] + 0.0271 * ( 6 - data.phot_g_mean_mag[cut])\n",
    "cut = (data.phot_g_mean_mag > 16)\n",
    "g_corr[cut] = data.phot_g_mean_mag[cut] - 0.032\n",
    "cut = (data.phot_g_mean_mag <= 16) & (data.phot_g_mean_mag > 6)\n",
    "g_corr[cut] = data.phot_g_mean_mag[cut] - (0.0032 * (data.phot_g_mean_mag[cut]-6))\n",
    "data.phot_g_mean_mag = g_corr\n",
    "\n",
    "g_corr = np.copy(data.phot_g_mean_mag2)\n",
    "cut = (data.phot_g_mean_mag2 <= 6)\n",
    "g_corr[cut] = data.phot_g_mean_mag2[cut] + 0.0271 * ( 6 - data.phot_g_mean_mag2[cut])\n",
    "cut = (data.phot_g_mean_mag2 > 16)\n",
    "g_corr[cut] = data.phot_g_mean_mag2[cut] - 0.032\n",
    "cut = (data.phot_g_mean_mag2 <= 16) & (data.phot_g_mean_mag2 > 6)\n",
    "g_corr[cut] = data.phot_g_mean_mag2[cut] - (0.0032 * (data.phot_g_mean_mag2[cut]-6))\n",
    "data.phot_g_mean_mag2 = g_corr\n",
    "# correct for the underestimated internal parallax uncertainty\n",
    "def external_uncertainty(internal_uncertainty):\n",
    "    k = 1.08\n",
    "    sigma_s = 0.043\n",
    "    return(np.sqrt( k**2 * internal_uncertainty**2 + sigma_s**2))\n",
    "data.parallax_error = external_uncertainty(data.parallax_error)\n",
    "data.parallax_error2 = external_uncertainty(data.parallax_error2)\n",
    "\n",
    "# correct for the zero parallax offset\n",
    "data.parallax += 0.05\n",
    "data.parallax2 += 0.05\n",
    "\n",
    "# increase minimum photometric noise to 0.03\n",
    "#data.phot_g_mean_mag_error[(data.phot_g_mean_mag_error<0.03)] = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_magnitude(mag1,mag2):\n",
    "    \"\"\"\n",
    "    adds two magnitude\n",
    "    \"\"\"\n",
    "    flux1 = np.power(10,-mag1*0.4)\n",
    "    flux2 = np.power(10,-mag2*0.4)\n",
    "    flux = flux1 + flux2\n",
    "    mag = -2.5 * np.log10(flux)\n",
    "    return(mag)\n",
    "\n",
    "def get_error(gmag,gmagerror,parallax,parallaxerror,rpmag,rpmagerror):\n",
    "    #propagate both errors\n",
    "    abs_g = np.random.normal(gmag,gmagerror,1000) + 5 * np.log10(np.divide(np.random.normal(parallax,parallaxerror,1000),100))\n",
    "    gd = np.mean(abs_g)\n",
    "    ge = np.std(abs_g) \n",
    "    # BPRP error\n",
    "    c = np.random.normal(gmag,gmagerror,1000) - np.random.normal(rpmag,rpmagerror,1000)\n",
    "    cd = np.mean(c)\n",
    "    ce = np.std(c)\n",
    "    return(gd,ge,cd,ce)\n",
    "\n",
    "# We have to define a log likelihood it measures how well the model fits the data (just multiplication of 2 Gaussians)\n",
    "def lnlikelihood(g_model,g_data,g_error,c_model,c_data,c_error):\n",
    "    '''\n",
    "    this is an unnormalised ln likelihood function\n",
    "    '''\n",
    "    g_like = -1*((g_model - g_data)**2)/(2*g_error**2)\n",
    "    c_like = -1*((c_model - c_data)**2)/(2*c_error**2)\n",
    "    return(g_like + c_like)\n",
    "\n",
    "\n",
    "def query(interpolator, parameter1, parameter2, parameter3):\n",
    "    '''\n",
    "    This queries the stellar model for 'spectroscopic' the input is:\n",
    "        log_teff, logg, feh\n",
    "    For 'physical' the input is:\n",
    "        log_mass, log_age, feh\n",
    "    Returns:\n",
    "        G and G-GRP\n",
    "    Appends the respective other parameters to the result\n",
    "    For 'physical' these are log_teff, logg and logL\n",
    "    For 'spectroscopic' these are mass, log_age and logL\n",
    "    '''\n",
    "    result = interpolator([parameter1,parameter2,parameter3])[0]\n",
    "    result = np.hstack((result[:2],result[-3:]))\n",
    "    return(result)\n",
    "\n",
    "def query_with_extinction(interpolator, parameter1, parameter2, parameter3, extinction, band_interpolation = 'linear'):\n",
    "    '''\n",
    "    This queries the stellar model for 'spectroscopic' the input is:\n",
    "        log_teff, logg, feh\n",
    "    For 'physical' the input is:\n",
    "        mass, log_age, feh\n",
    "    Returns:\n",
    "        G and G-GRP\n",
    "    If return_other than the respective other stellar astrophysical parameters are appended to the return:\n",
    "    For 'physical' these are log_teff, logg and logL\n",
    "    For 'spectroscopic' these are mass, log_age and logL\n",
    "    band_interpolation: 'linear' is 50 times faster, 'cubic' is more accurate. For low extinction (< 6) the linear should be a good approximation\n",
    "    '''                \n",
    "    av_axis = np.array([0,1,2,3,5,10])        \n",
    "    rs = interpolator([parameter1,parameter2,parameter3])[0]\n",
    "    g = np.array([rs[0],rs[2],rs[4],rs[6],rs[8],rs[10]])\n",
    "    grp = np.array([rs[1],rs[3],rs[5],rs[7],rs[9],rs[11]])\n",
    "    if band_interpolation == 'linear':\n",
    "        gres = np.interp(extinction,av_axis,g)\n",
    "        grpres = np.interp(extinction,av_axis,grp)\n",
    "    elif band_interpolation == 'cubic':\n",
    "        from scipy.interpolate import interp1d                \n",
    "        gres = interp1d(av_axis,g, kind = 'cubic', copy = False, bounds_error=False, fill_value='extrapolate', assume_sorted = True)(extinction)           \n",
    "        grpres = interp1d(av_axis,grp, kind = 'cubic', copy = False, bounds_error=False, fill_value='extrapolate', assume_sorted = True)(extinction)           \n",
    "    result = np.hstack((gres,grpres,rs[-3:]))\n",
    "    return(result)\n",
    "\n",
    "\n",
    "\n",
    "def initialize_mcmc(index_g_color, isochrones, g, color, nwalkers):\n",
    "    \"\"\"\n",
    "    This function returns the closest parsec models in observable space (G,BP-RP)\n",
    "    and returns the initial walker positions for the MCMC containing mass, age and feh of the #walkers closest models\n",
    "    INPUT:\n",
    "       index_g_color = KDTree of the parsec models in abs_g and bp-rp\n",
    "       isochrones = the parsec isochrones as downloaded\n",
    "       g = abs_g of the star\n",
    "       color = color of the star\n",
    "       nwalkers = number of closest models to look for in order to initialise that number of walkers\n",
    "    \n",
    "    OUTPUT:\n",
    "       p0 = the stacked array for MCMC initialization where for each walker mass, age and feh information of the model are given.\n",
    "    \"\"\"\n",
    "    cut = index_g_color.query(np.c_[g,color],nwalkers)[1][0]\n",
    "    log_mass = isochrones[cut].log_mass\n",
    "    log_age = isochrones[cut].log_age\n",
    "    meh_ini = isochrones[cut].meh_ini\n",
    "    log_mass += np.random.normal(0,0.02,size = nwalkers)\n",
    "    log_age += np.random.normal(0,0.02,size = nwalkers)\n",
    "    meh_ini += np.random.normal(0,0.02,size = nwalkers)\n",
    "    return(np.c_[log_mass,log_age,meh_ini])\n",
    "\n",
    "def imf(mass):\n",
    "    \"\"\"\n",
    "    IMF prior    \n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    if mass < 1:\n",
    "        result = np.power(mass,-1.6)\n",
    "    elif mass >= 1:\n",
    "        result = np.power(mass,-3.0)\n",
    "    if mass < 0.08 or mass > 50:\n",
    "        result = -np.inf\n",
    "    result = np.log(result)\n",
    "    if np.isnan(result):\n",
    "        result = -np.inf\n",
    "    return(result)\n",
    "\n",
    "\n",
    "def sfr(log_age):\n",
    "    \"\"\"\n",
    "    flat prior in linear age\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    if log_age > 10.12 or log_age < 6.6:\n",
    "        return(-np.inf)\n",
    "    else:\n",
    "        age = np.power(10,log_age)\n",
    "        # Jakobian factor\n",
    "        result = np.divide(age,np.log10(np.exp(1)))\n",
    "        return(np.log(result))\n",
    "\n",
    "\n",
    "def mdf(feh):\n",
    "    \"\"\"\n",
    "    flat prior for now\n",
    "    \"\"\"\n",
    "    result = 0\n",
    "    if feh > 0.33 or feh < -1.5:\n",
    "        result = -np.inf\n",
    "    return(result)\n",
    "\n",
    "def prior(mass,log_age,feh):\n",
    "    lnmass = imf(mass)\n",
    "    lnage = sfr(log_age)\n",
    "    lnfeh = mdf(feh)\n",
    "    return(lnmass + lnage + lnfeh)\n",
    "\n",
    "def lnprob(x, ivar):\n",
    "    gd,ge,cd,ce = ivar\n",
    "    log_mass,log_age,meh_ini = x\n",
    "    gm,cm,log_teff,log_grav,log_lum = query(interp,log_mass, log_age, meh_ini)\n",
    "    mass = np.power(10,log_mass)\n",
    "    lnlike = lnlikelihood(gm,gd,ge,cm,cd,ce)\n",
    "    lnprior = prior(mass,log_age,meh_ini)\n",
    "    \n",
    "    if np.isnan(lnlike):\n",
    "        lnlike = -np.inf\n",
    "    if np.isnan(lnprior):\n",
    "        lnprior = -np.inf\n",
    "    return(lnlike + lnprior, np.hstack((log_teff,log_grav,log_lum)))\n",
    "\n",
    "def printout(d, component,sampler):\n",
    "    d[\"mean_acceptance_fraction\" + component] = np.median(sampler.acceptance_fraction)\n",
    "    d[\"mass\" + component] = np.power(10,np.percentile(sampler.get_chain(flat=True)[:,0],50))\n",
    "    d[\"mass_lower\" + component] = np.power(10,np.percentile(sampler.get_chain(flat=True)[:,0],16))\n",
    "    d[\"mass_upper\" + component] = np.power(10,np.percentile(sampler.get_chain(flat=True)[:,0],84))\n",
    "    d[\"age\" + component] = np.power(10,np.percentile(sampler.get_chain(flat=True)[:,1],50))/1e9\n",
    "    d[\"age_lower\" + component] = np.power(10,np.percentile(sampler.get_chain(flat=True)[:,1],16))/1e9\n",
    "    d[\"age_upper\" + component] = np.power(10,np.percentile(sampler.get_chain(flat=True)[:,1],84))/1e9\n",
    "    d[\"feh\" + component] = np.percentile(sampler.get_chain(flat=True)[:,2],50)\n",
    "    d[\"feh_lower\" + component] = np.percentile(sampler.get_chain(flat=True)[:,2],16)\n",
    "    d[\"feh_upper\" + component] = np.percentile(sampler.get_chain(flat=True)[:,2],84)\n",
    "    d[\"teff\" + component] = np.power(10,np.percentile(sampler.get_blobs(flat=True)[:,0],50))\n",
    "    d[\"teff_lower\" + component] = np.power(10,np.percentile(sampler.get_blobs(flat=True)[:,0],16))\n",
    "    d[\"teff_upper\" + component] = np.power(10,np.percentile(sampler.get_blobs(flat=True)[:,0],84))\n",
    "    d[\"logg\" + component] = np.percentile(sampler.get_blobs(flat=True)[:,1],50)\n",
    "    d[\"logg_lower\" + component] = np.percentile(sampler.get_blobs(flat=True)[:,1],16)\n",
    "    d[\"logg_upper\" + component] = np.percentile(sampler.get_blobs(flat=True)[:,1],84)\n",
    "    d[\"logl\" + component] = np.percentile(sampler.get_blobs(flat=True)[:,2],50)\n",
    "    d[\"logl_lower\" + component] = np.percentile(sampler.get_blobs(flat=True)[:,2],16)\n",
    "    d[\"logl_upper\" + component] = np.percentile(sampler.get_blobs(flat=True)[:,2],84)\n",
    "    d[\"lnprob\" + component] = np.percentile(sampler.get_log_prob(flat=True),50)\n",
    "    d[\"lnprob_lower\" + component] = np.percentile(sampler.get_log_prob(flat=True),16)\n",
    "    d[\"lnprob_upper\" + component] = np.percentile(sampler.get_log_prob(flat=True),84)\n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = fits.getdata(\"../data/isochrones/reduced/parsec_dr3_original_sparse_feh_20th.fits\")\n",
    "pa = pa.view(np.recarray)\n",
    "input_grid = np.c_[pa.log_mass,pa.log_age,pa.meh_ini]\n",
    "output_grid = np.c_[pa.g0,pa.grp0,pa.g1,pa.grp1,pa.g2,pa.grp2,pa.g3,pa.grp3,pa.g5,pa.grp5,pa.g10,pa.grp10,pa.log_teff,pa.log_grav,pa.log_lum]\n",
    "grid = Delaunay(input_grid)\n",
    "interp = LinearNDInterpolator(grid,output_grid, rescale = False)\n",
    "\n",
    "# Initialization: in order to pick the first parsec models to start MCMC from\n",
    "init_parsec_index = cKDTree(np.c_[pa.g0,pa.grp0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###\n",
    "def make_entry(i):\n",
    "    components = [\"\",\"2\"]\n",
    "    ndim, nwalkers = 3, 6\n",
    "    try:\n",
    "        for component in components:\n",
    "            # First component\n",
    "            ivar = get_error(data[\"phot_g_mean_mag\" + component][i],data[\"phot_g_mean_mag_error\" + component][i],\n",
    "                             data[\"parallax\" + component][i],data[\"parallax_error\" + component][i], \n",
    "                             data[\"phot_rp_mean_mag\" + component][i], data[\"phot_rp_mean_mag_error\" + component][i])\n",
    "            # Initialization with models that are closest in observable space\n",
    "            p0 = initialize_mcmc(init_parsec_index, pa, ivar[0], ivar[2], nwalkers)\n",
    "\n",
    "            sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[ivar])\n",
    "            pos, prob, state, blobs = sampler.run_mcmc(p0, 200)\n",
    "\n",
    "            sampler.reset()\n",
    "            sampler.run_mcmc(pos, 101)\n",
    "\n",
    "            data[i] = printout(data[i],component, sampler)\n",
    "            #for item in ['lnprob','teff','logg','feh','mass','age','a0']:\n",
    "            #    print(item,data[i][item + component])\n",
    "    except Exception as e:\n",
    "        \n",
    "        print('simple initialisation failed')\n",
    "        print(repr(e))\n",
    "        try:\n",
    "            for component in components:\n",
    "                # First component\n",
    "                ivar = get_error(data[\"phot_g_mean_mag\" + component][i],data[\"phot_g_mean_mag_error\" + component][i],\n",
    "                                 data[\"parallax\" + component][i],data[\"parallax_error\" + component][i], \n",
    "                                 data[\"phot_rp_mean_mag\" + component][i], data[\"phot_rp_mean_mag_error\" + component][i])\n",
    "                # 1)Random initialization\n",
    "                p0_ind = np.random.choice(len(pa),replace = False, size = nwalkers)\n",
    "                p0= np.c_[pa[p0_ind]['log_mass'],pa[p0_ind]['log_age'],pa[p0_ind]['meh_ini']]\n",
    "\n",
    "                sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob, args=[ivar])\n",
    "                pos, prob, state, blobs = sampler.run_mcmc(p0, 2000)\n",
    "\n",
    "                sampler.reset()\n",
    "                sampler.run_mcmc(pos, 101)\n",
    "\n",
    "                data[i] = printout(data[i],component, sampler)\n",
    "        except Exception as e:\n",
    "            print('random initialisation also failed. No results for binary with index: ', i)\n",
    "            print(repr(e))\n",
    "            return(data[i])\n",
    "    return(data[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rybizki/anaconda3/lib/python3.7/site-packages/emcee/moves/red_blue.py:99: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lnpdiff = f + nlp - state.log_prob[j]\n",
      "/home/rybizki/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:111: RuntimeWarning: invalid value encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 s ± 392 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor j in range(10):\\n    d,s = make_entry(j)\\n    for i in range(6):\\n        plt.plot(s.chain[i,:,0])\\n    plt.show()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit make_entry(10)\n",
    "'''\n",
    "for j in range(10):\n",
    "    d,s = make_entry(j)\n",
    "    for i in range(6):\n",
    "        plt.plot(s.chain[i,:,0])\n",
    "    plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (<ipython-input-7-c92c607517c7>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-c92c607517c7>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    result = pool.map(make_entry, range(len(data)))\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break\n",
    "\n",
    "pool = Pool(processes = None)\n",
    "result = pool.map(make_entry, range(len(data)))\n",
    "\n",
    "for j in range(len(data)):\n",
    "    data[j] = result[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fits.writeto(\"../data/value_added_3params_per_component.fits\",data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
